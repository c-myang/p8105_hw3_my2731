P8105 Homework 3
================
October 15th, 2022

## Problem 1: Instacart Data

We will be working with the “The Instacart Online Grocery Shopping
Dataset 2017”.

### Data overview and description

``` r
data("instacart")

instacart
```

    ## # A tibble: 1,384,617 × 15
    ##    order_id product_id add_to_…¹ reord…² user_id eval_…³ order…⁴ order…⁵ order…⁶
    ##       <int>      <int>     <int>   <int>   <int> <chr>     <int>   <int>   <int>
    ##  1        1      49302         1       1  112108 train         4       4      10
    ##  2        1      11109         2       1  112108 train         4       4      10
    ##  3        1      10246         3       0  112108 train         4       4      10
    ##  4        1      49683         4       0  112108 train         4       4      10
    ##  5        1      43633         5       1  112108 train         4       4      10
    ##  6        1      13176         6       0  112108 train         4       4      10
    ##  7        1      47209         7       0  112108 train         4       4      10
    ##  8        1      22035         8       1  112108 train         4       4      10
    ##  9       36      39612         1       0   79431 train        23       6      18
    ## 10       36      19660         2       1   79431 train        23       6      18
    ## # … with 1,384,607 more rows, 6 more variables: days_since_prior_order <int>,
    ## #   product_name <chr>, aisle_id <int>, department_id <int>, aisle <chr>,
    ## #   department <chr>, and abbreviated variable names ¹​add_to_cart_order,
    ## #   ²​reordered, ³​eval_set, ⁴​order_number, ⁵​order_dow, ⁶​order_hour_of_day

The dataset contains information about online grocery orders made
through Instacart. There 1,384,617 observations of 15 variables, where
each row in the dataset is a product from an order. Each order is
associated with a unique order ID number and order ID. The variables
`order_hour_of_day` and `order_dow` describe the time (hour of day and
day of the week) orders were made. Each row also contains information
about each product, such as `product_name`, `aisle`, and `department` of
the product. The variable `reordered` indicates whether a product has
been purchased by a user in the past, and `add_to_cart_order` indicates
the order an item was placed in the cart.

For example, for `order_id == 1`, we can see the order was made at 10AM
on a Thursday, 4 out of the 8 products are reorders, and that most of
the products came from the produce and dairy eggs department.

## Data exploration

Now, we want to conduct some basic EDA and answer some questions about
the `instacart` data.

1.  Number of aisles

Using `group_by`, and `summarise`, we can determine the number of
aisles, and the most popular aisles customers order from in the dataset.

``` r
aisles = instacart %>% 
  group_by(aisle_id, aisle) %>% 
  summarise(
    n_obs = n()
  ) %>% 
  arrange(desc(n_obs))

aisles
```

    ## # A tibble: 134 × 3
    ## # Groups:   aisle_id [134]
    ##    aisle_id aisle                          n_obs
    ##       <int> <chr>                          <int>
    ##  1       83 fresh vegetables              150609
    ##  2       24 fresh fruits                  150473
    ##  3      123 packaged vegetables fruits     78493
    ##  4      120 yogurt                         55240
    ##  5       21 packaged cheese                41699
    ##  6      115 water seltzer sparkling water  36617
    ##  7       84 milk                           32644
    ##  8      107 chips pretzels                 31269
    ##  9       91 soy lactosefree                26240
    ## 10      112 bread                          23635
    ## # … with 124 more rows

There are 134 different aisles. The most popular aisles customers order
from are fresh vegetables, fresh fruits, and packaged vegetables fruits,
respectively.

2.  Plotting number of items ordered in each aisle

``` r
plot_aisles = aisles %>% 
  filter(n_obs >= 10000) %>% 
  ggplot(aes(x = reorder(aisle, n_obs), y = n_obs)) +
  geom_bar(stat = "identity") + 
  coord_flip() +
  labs(
    title = "Number of Instacart items ordered by aisle",
    x = "Aisle",
    y = "Number of items ordered",
    caption = "Data from The Instacart Online Grocery Shopping Dataset 2017 in the p8105.datasets package"
  )

plot_aisles
```

![](p8105_hw3_my2731_files/figure-gfm/plot_aisles-1.png)<!-- -->

Through the bar plot, we can confirm that for aisles with over 10,000
items ordered, the most popular aisles are fresh fruits and vegetables,
and the least popular aisles are butter, oils and vinegars, and dry
pasta.

3.  Popular items

Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
Include the number of times each item is ordered in your table.

``` r
pop_items = instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarise(n_obs = n()) %>% 
  arrange(desc(n_obs),.by_group = TRUE) %>% 
  slice(1)

knitr::kable(pop_items)
```

| aisle                      | product_name                                    | n_obs |
|:---------------------------|:------------------------------------------------|------:|
| baking ingredients         | Light Brown Sugar                               |   157 |
| dog food care              | Organix Grain Free Chicken & Vegetable Dog Food |    14 |
| packaged vegetables fruits | Organic Baby Spinach                            |  3324 |

4.  Mean ordering times

Make a table showing the mean hour of the day at which Pink Lady Apples
and Coffee Ice Cream are ordered on each day of the week; format this
table for human readers (i.e. produce a 2 x 7 table).

## Problem 2: Accelerometer Data

### Clean and load data

In this problem, we will load, clean, and tidy the `accel_data.csv`
dataset, which contains five weeks of accelerometer data collected on a
63 year-old male with BMI 25, admitted to the Advanced Cardiac Care
Center of Columbia University Medical Center and diagnosed with
congestive heart failure (CHF).

We will apply snake case to all the variables, add a logical `weekend`
variable that is `TRUE` if `day == c("Saturday", "Sunday")` and `FALSE`
otherwise.

``` r
accel_data =
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekend = ifelse(day == "Saturday" | day == "Sunday", TRUE, FALSE)) %>% 
  relocate(weekend, .after = day)

accel_data
```

    ## # A tibble: 35 × 1,444
    ##     week day_id day      weekend activ…¹ activ…² activ…³ activ…⁴ activ…⁵ activ…⁶
    ##    <dbl>  <dbl> <chr>    <lgl>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1     1      1 Friday   FALSE      88.4    82.2    64.4    70.0    75.0    66.3
    ##  2     1      2 Monday   FALSE       1       1       1       1       1       1  
    ##  3     1      3 Saturday TRUE        1       1       1       1       1       1  
    ##  4     1      4 Sunday   TRUE        1       1       1       1       1       1  
    ##  5     1      5 Thursday FALSE      47.4    48.8    46.9    35.8    49.0    44.8
    ##  6     1      6 Tuesday  FALSE      64.8    59.5    73.7    45.7    42.4    58.4
    ##  7     1      7 Wednesd… FALSE      71.1   103.     68.5    45.4    37.8    18.3
    ##  8     2      8 Friday   FALSE     675     542    1010     779     509     106  
    ##  9     2      9 Monday   FALSE     291     335     393     335     263     675  
    ## 10     2     10 Saturday TRUE       64      11       1       1       1       1  
    ## # … with 25 more rows, 1,434 more variables: activity_7 <dbl>,
    ## #   activity_8 <dbl>, activity_9 <dbl>, activity_10 <dbl>, activity_11 <dbl>,
    ## #   activity_12 <dbl>, activity_13 <dbl>, activity_14 <dbl>, activity_15 <dbl>,
    ## #   activity_16 <dbl>, activity_17 <dbl>, activity_18 <dbl>, activity_19 <dbl>,
    ## #   activity_20 <dbl>, activity_21 <dbl>, activity_22 <dbl>, activity_23 <dbl>,
    ## #   activity_24 <dbl>, activity_25 <dbl>, activity_26 <dbl>, activity_27 <dbl>,
    ## #   activity_28 <dbl>, activity_29 <dbl>, activity_30 <dbl>, …

The dataset contains 35 observations of 1444 variables, where each row
describes the activity counts for all minutes of each day. The weekday
of observation is indicated by `day`, and has a unique `day_id`. `week`
indicates the week of observation, and the `weekend` indicates whether
observation falls on a weekend. The variables `activity_*` are the
activity counts for all 1440 minutes of a 24-hour day, starting at
midnight.

### Aggregate across minutes

Using `rowSums` and `across` within the `mutate` function, we can
compute the sum across minutes for each day to get the total activity
over the day.

``` r
accel_data = accel_data %>%
  mutate(total_activity = rowSums(across(activity_1:activity_1440))) %>% 
  relocate(total_activity, .after = weekend) 

accel_data %>% 
  select(week:total_activity) %>% 
  knitr::kable()
```

| week | day_id | day       | weekend | total_activity |
|-----:|-------:|:----------|:--------|---------------:|
|    1 |      1 | Friday    | FALSE   |      480542.62 |
|    1 |      2 | Monday    | FALSE   |       78828.07 |
|    1 |      3 | Saturday  | TRUE    |      376254.00 |
|    1 |      4 | Sunday    | TRUE    |      631105.00 |
|    1 |      5 | Thursday  | FALSE   |      355923.64 |
|    1 |      6 | Tuesday   | FALSE   |      307094.24 |
|    1 |      7 | Wednesday | FALSE   |      340115.01 |
|    2 |      8 | Friday    | FALSE   |      568839.00 |
|    2 |      9 | Monday    | FALSE   |      295431.00 |
|    2 |     10 | Saturday  | TRUE    |      607175.00 |
|    2 |     11 | Sunday    | TRUE    |      422018.00 |
|    2 |     12 | Thursday  | FALSE   |      474048.00 |
|    2 |     13 | Tuesday   | FALSE   |      423245.00 |
|    2 |     14 | Wednesday | FALSE   |      440962.00 |
|    3 |     15 | Friday    | FALSE   |      467420.00 |
|    3 |     16 | Monday    | FALSE   |      685910.00 |
|    3 |     17 | Saturday  | TRUE    |      382928.00 |
|    3 |     18 | Sunday    | TRUE    |      467052.00 |
|    3 |     19 | Thursday  | FALSE   |      371230.00 |
|    3 |     20 | Tuesday   | FALSE   |      381507.00 |
|    3 |     21 | Wednesday | FALSE   |      468869.00 |
|    4 |     22 | Friday    | FALSE   |      154049.00 |
|    4 |     23 | Monday    | FALSE   |      409450.00 |
|    4 |     24 | Saturday  | TRUE    |        1440.00 |
|    4 |     25 | Sunday    | TRUE    |      260617.00 |
|    4 |     26 | Thursday  | FALSE   |      340291.00 |
|    4 |     27 | Tuesday   | FALSE   |      319568.00 |
|    4 |     28 | Wednesday | FALSE   |      434460.00 |
|    5 |     29 | Friday    | FALSE   |      620860.00 |
|    5 |     30 | Monday    | FALSE   |      389080.00 |
|    5 |     31 | Saturday  | TRUE    |        1440.00 |
|    5 |     32 | Sunday    | TRUE    |      138421.00 |
|    5 |     33 | Thursday  | FALSE   |      549658.00 |
|    5 |     34 | Tuesday   | FALSE   |      367824.00 |
|    5 |     35 | Wednesday | FALSE   |      445366.00 |

The table above shows the totals for each day. From first glance, we see
that the total activity is higher on weekends compared to the weekdays
We can also see that as time progresses, activity levels appear to
slightly decrease.

### Plotting activity through the day

Accelerometer data allows the inspection activity over the course of the
day. Using `summarise`, we can get the mean activity counts for each
minute of the day, for each day of the week.

``` r
daily_activity = accel_data %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    values_to = "activity",
    names_prefix = "activity_") %>% 
  mutate(minute = as.numeric(minute)) %>% 
  group_by(day, minute) %>% 
  summarise(mean_activity = mean(activity))
```

Based on this data, we can plot the mean 24-hour activity time course,
according to the day of the week.

``` r
activity_plot = daily_activity %>% 
  ggplot(aes(x = minute, y = mean_activity, color = day)) + 
  geom_point(alpha = 0.2) + 
  geom_smooth(se = FALSE) + 
  labs(
    x = "Minute",
    y = "Mean activity",
    title = "Mean daily accelerometer activity by day of the week",
    caption = "Data come from the accel_data.csv dataset",
    color = "Day"
  ) + 
  scale_x_continuous(limits = c(0, 1400)) + 
  scale_y_continuous(limits = c(0, 2300)) + 
  viridis::scale_color_viridis(discrete = TRUE)

activity_plot
```

![](p8105_hw3_my2731_files/figure-gfm/activity_plot-1.png)<!-- -->

Describe in words any patterns or conclusions you can make based on this
graph.
